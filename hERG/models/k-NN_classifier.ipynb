{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "from itertools import islice\n",
    "\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit.Chem import PandasTools\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import rdMolDescriptors as rdMD\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import recall_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_morgan_fp(mol):\n",
    "    \"\"\"\n",
    "    Returns the RDKit Morgan fingerprint for a molecule\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    fp = rdMD.GetMorganFingerprintAsBitVect(mol, 2, nBits=1024, useFeatures=False, bitInfo=info)\n",
    "    return fp\n",
    "\n",
    "def tanimoto(F1,F2):\n",
    "    \"\"\"\n",
    "    Returns tanimoto similarity score for two fingerprints\n",
    "    \"\"\"\n",
    "    Na=float(F1.count(\"1\"))\n",
    "    Nb=float(F2.count(\"1\"))\n",
    "    index_Na = [i for i, x in enumerate(F1) if x == \"1\"]\n",
    "    index_Nb = [i for i, x in enumerate(F2) if x == \"1\"]\n",
    "    pos=list(set(index_Na).intersection(index_Nb))\n",
    "    Nc=float(len(pos))\n",
    "    tc=(Nc)/(Na+Nb-Nc)\n",
    "    tc=round(tc,1)\n",
    "    return tc\n",
    "\n",
    "def take(n, iterable):\n",
    "    \"\"\"\n",
    "    Return first n items of the iterable as a list\n",
    "    \"\"\"\n",
    "    return list(islice(iterable, n))\n",
    "\n",
    "def getNeighbors(x_train, testInstance):\n",
    "    \"\"\"\n",
    "    Returns k neighbors with their similarity scores and activity classes\n",
    "    \"\"\"\n",
    "    similarity = {}\n",
    "    sorted_similarity = {}\n",
    "    ac = {}\n",
    "    k_sim_scores = []\n",
    "    k_neighbors = []\n",
    "    for j in range(len(x_train)):\n",
    "        #sim = tanimoto(testInstance,x_train[j])\n",
    "        #similarity[(x_train.index[j])] = sim\n",
    "        dice = DataStructs.DiceSimilarity(testInstance, x_train[j])\n",
    "        dice = round(dice, 2)\n",
    "        similarity[(x_train.index[j])] = dice\n",
    "        ac[(y_train.index[j])] = y_train[j]\n",
    "    sorted_similarity = sorted(similarity.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    k_sim_scores = take(k[n], sorted_similarity)\n",
    "    return ac,dict(k_sim_scores)\n",
    "\n",
    "def get_prediction(k_sim_scores,ac):\n",
    "    \"\"\"\n",
    "    Returns predicted score and class for a testset compound\n",
    "    \"\"\"\n",
    "    k = len(k_sim_scores)\n",
    "    maxi = ((k/2)+1)\n",
    "    active=0\n",
    "    inactive=0\n",
    "    pred_class = []\n",
    "    active_score = []\n",
    "    inactive_score = []\n",
    "    pred_score = []\n",
    "    for key in k_sim_scores:\n",
    "        if key in ac and ac[key] == 1:\n",
    "            active += 1\n",
    "            active_score.append(k_sim_scores[key])\n",
    "        else:\n",
    "            inactive += 1\n",
    "            inactive_score.append(k_sim_scores[key])\n",
    "    if active >= maxi:\n",
    "        pred_class.append(1)\n",
    "        mean_tc = sum(active_score)/len(active_score)\n",
    "        pred_score.append(round(mean_tc,2))\n",
    "    else:\n",
    "        pred_class.append(0)\n",
    "        mean_tc = sum(inactive_score)/len(inactive_score)\n",
    "        mean_tc = 1-mean_tc\n",
    "        pred_score.append(round(mean_tc,2))\n",
    "    \n",
    "    return pred_class,pred_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The data file should contain three columns \n",
    "# 1. molecule ID;\n",
    "# 2. canonical SMILES; and \n",
    "# 3. activity (which is either 1 or 0)\n",
    "\n",
    "# reading the data file into a pandas data frame\n",
    "df=pd.read_csv('/Publications/hERG/datasets/chembl_training_T3.csv', header=0, index_col=0)\n",
    "\n",
    "# Build ROMol objects \n",
    "PandasTools.AddMoleculeColumnToFrame(df, smilesCol='can_smiles')\n",
    "\n",
    "# Remove molecules that could not be parsed from SMILES\n",
    "df = df[~df.ROMol.isnull()]\n",
    "\n",
    "# Calculate fingerprints and store them in df\n",
    "# Note: if additional fingerprints are needed that are not available in RDkit, they must be imported with the data\n",
    "df['fp'] = df.apply(lambda x: get_morgan_fp(x['ROMol']), axis=1)\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create X variable (=features i.e. molecular fingerprints)\n",
    "x = df['fp']\n",
    "#print(X.shape)\n",
    "\n",
    "# create Y variable (=activity values i.e. blocker;1 or non-blocker;0)\n",
    "y = df['ac']\n",
    "#print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:\t\t0.91 +/- 0.01\n",
      "Sensitivity:\t0.88 +/- 0.02\n",
      "Specificity:\t0.87 +/- 0.01\n"
     ]
    }
   ],
   "source": [
    "# Different k parameter for cross-validation\n",
    "k=[1]\n",
    "# if multiple k parameters are needed, then initialize k as k=[1,3,5,10]\n",
    "for n in range(len(k)):\n",
    "    \n",
    "    # Initialize performance measures\n",
    "    sens     = np.array([])\n",
    "    spec     = np.array([])\n",
    "    mean_auc = np.array([])\n",
    "    \n",
    "    # 10-fold cross-validation split\n",
    "    sss = StratifiedShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for train_index, test_index in sss.split(x,y):\n",
    "        # Split data to training and test set\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        z += 1\n",
    "        pred_class = []\n",
    "        prediction = []\n",
    "        pred_prob = []\n",
    "        y_true = []\n",
    "        \n",
    "        # Training a k-NN classifier and predicting the test set\n",
    "        for i in range(len(x_test)):\n",
    "            ac = {}\n",
    "            k_sim_scores = {}\n",
    "            ac,k_sim_scores = getNeighbors(x_train, x_test[i])\n",
    "            prediction = get_prediction(k_sim_scores, ac)\n",
    "            pred_class.append(int(prediction[0][0]))\n",
    "            pred_prob.append(prediction[1][0])\n",
    "            y_true.append(y_test[i])\n",
    "            \n",
    "        # Append performance measures\n",
    "        sens = np.append(sens, recall_score(y_true, pred_class, pos_label=1))\n",
    "        spec = np.append(spec, recall_score(y_true, pred_class, pos_label=0))\n",
    "        mean_auc = np.append(mean_auc, roc_auc_score(y_true, pred_prob))\n",
    "    \n",
    "    # 10-fold cross-validation performance\n",
    "    print('AUC:\\t\\t%.2f +/- %.2f' % (mean_auc.mean(), mean_auc.std()))\n",
    "    print('Sensitivity:\\t%.2f +/- %.2f' % (sens.mean(), sens.std()))\n",
    "    print('Specificity:\\t%.2f +/- %.2f' % (spec.mean(), spec.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
